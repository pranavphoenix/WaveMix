{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch, math\nimport torchvision\nimport torchvision.transforms as transforms\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom PIL import Image\n\nimport time\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data import Dataset\nimport torch.optim as optim\n!pip install torchsummary\nfrom torchsummary import summary\n!pip install einops\nfrom math import ceil\nimport pywt\n\nfrom einops import rearrange, repeat\nfrom einops.layers.torch import Rearrange\n\nfrom torch import nn, einsum\nfrom einops import rearrange, repeat\nfrom einops.layers.torch import Rearrange\n\n# helpers\nfrom einops import reduce\n\ntransform = transforms.Compose(\n        [transforms.ToTensor(),\n     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n\nbatch_size = 512\n\ntrainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n                                        download=True, transform=transform)\ntrainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n                                          shuffle=True, num_workers=2)\n\ntestset = torchvision.datasets.CIFAR10(root='./data', train=False,\n                                       download=True, transform=transform)\ntestloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n                                         shuffle=False, num_workers=2)\n\nclasses = ('plane', 'car', 'bird', 'cat',\n           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\ndef accuracy(output, target, topk=(1,5)):\n    \"\"\"Computes the precision@k for the specified values of k\n    prec1, prec5 = accuracy(output.data, target, topk=(1, 5))\n    \"\"\"\n    maxk = max(topk)\n         # sizefunction: the number of total elements\n    batch_size = target.size(0) \n \n         # topk function selects the number of k before output\n    _, pred = output.topk(maxk, 1, True, True)\n         ##########Do not understand t()k\n    pred = pred.t()\n    correct = pred.eq(target.view(1, -1).expand_as(pred))   \n    res = []\n    for k in topk:\n        correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n        res.append(correct_k.mul_(100.0 / batch_size))\n    return res","metadata":{"id":"cbWZ3q8DSBBU","outputId":"3b52c581-06a6-40bd-8f3a-ea0a89fe8549","execution":{"iopub.status.busy":"2021-09-30T13:37:23.696702Z","iopub.execute_input":"2021-09-30T13:37:23.698035Z","iopub.status.idle":"2021-09-30T13:37:59.380515Z","shell.execute_reply.started":"2021-09-30T13:37:23.697896Z","shell.execute_reply":"2021-09-30T13:37:59.379311Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn.functional as F\nimport numpy as np\nfrom torch.autograd import Function\nimport pywt\nimport torch.nn as nn\nimport functools\n\ndef sfb1d(lo, hi, g0, g1, mode='zero', dim=-1):\n    \"\"\" 1D synthesis filter bank of an image tensor\n    \"\"\"\n    C = lo.shape[1]\n    d = dim % 4\n    # If g0, g1 are not tensors, make them. If they are, then assume that they\n    # are in the right order\n    if not isinstance(g0, torch.Tensor):\n        g0 = torch.tensor(np.copy(np.array(g0).ravel()),\n                          dtype=torch.float, device=lo.device)\n    if not isinstance(g1, torch.Tensor):\n        g1 = torch.tensor(np.copy(np.array(g1).ravel()),\n                          dtype=torch.float, device=lo.device)\n    L = g0.numel()\n    shape = [1,1,1,1]\n    shape[d] = L\n    N = 2*lo.shape[d]\n    # If g aren't in the right shape, make them so\n    if g0.shape != tuple(shape):\n        g0 = g0.reshape(*shape)\n    if g1.shape != tuple(shape):\n        g1 = g1.reshape(*shape)\n\n    s = (2, 1) if d == 2 else (1,2)\n    g0 = torch.cat([g0]*C,dim=0)\n    g1 = torch.cat([g1]*C,dim=0)\n    if mode == 'per' or mode == 'periodization':\n        y = F.conv_transpose2d(lo, g0, stride=s, groups=C) + \\\n            F.conv_transpose2d(hi, g1, stride=s, groups=C)\n        if d == 2:\n            y[:,:,:L-2] = y[:,:,:L-2] + y[:,:,N:N+L-2]\n            y = y[:,:,:N]\n        else:\n            y[:,:,:,:L-2] = y[:,:,:,:L-2] + y[:,:,:,N:N+L-2]\n            y = y[:,:,:,:N]\n        y = roll(y, 1-L//2, dim=dim)\n    else:\n        if mode == 'zero' or mode == 'symmetric' or mode == 'reflect' or \\\n                mode == 'periodic':\n            pad = (L-2, 0) if d == 2 else (0, L-2)\n            y = F.conv_transpose2d(lo, g0, stride=s, padding=pad, groups=C) + \\\n                F.conv_transpose2d(hi, g1, stride=s, padding=pad, groups=C)\n        else:\n            raise ValueError(\"Unkown pad type: {}\".format(mode))\n\n    return y\n\ndef reflect(x, minx, maxx):\n    \"\"\"Reflect the values in matrix *x* about the scalar values *minx* and\n    *maxx*.  Hence a vector *x* containing a long linearly increasing series is\n    converted into a waveform which ramps linearly up and down between *minx*\n    and *maxx*.  If *x* contains integers and *minx* and *maxx* are (integers +\n    0.5), the ramps will have repeated max and min samples.\n    .. codeauthor:: Rich Wareham <rjw57@cantab.net>, Aug 2013\n    .. codeauthor:: Nick Kingsbury, Cambridge University, January 1999.\n    \"\"\"\n    x = np.asanyarray(x)\n    rng = maxx - minx\n    rng_by_2 = 2 * rng\n    mod = np.fmod(x - minx, rng_by_2)\n    normed_mod = np.where(mod < 0, mod + rng_by_2, mod)\n    out = np.where(normed_mod >= rng, rng_by_2 - normed_mod, normed_mod) + minx\n    return np.array(out, dtype=x.dtype)\n\ndef mode_to_int(mode):\n    if mode == 'zero':\n        return 0\n    elif mode == 'symmetric':\n        return 1\n    elif mode == 'per' or mode == 'periodization':\n        return 2\n    elif mode == 'constant':\n        return 3\n    elif mode == 'reflect':\n        return 4\n    elif mode == 'replicate':\n        return 5\n    elif mode == 'periodic':\n        return 6\n    else:\n        raise ValueError(\"Unkown pad type: {}\".format(mode))\n\ndef int_to_mode(mode):\n    if mode == 0:\n        return 'zero'\n    elif mode == 1:\n        return 'symmetric'\n    elif mode == 2:\n        return 'periodization'\n    elif mode == 3:\n        return 'constant'\n    elif mode == 4:\n        return 'reflect'\n    elif mode == 5:\n        return 'replicate'\n    elif mode == 6:\n        return 'periodic'\n    else:\n        raise ValueError(\"Unkown pad type: {}\".format(mode))\n\ndef afb1d(x, h0, h1, mode='zero', dim=-1):\n    \"\"\" 1D analysis filter bank (along one dimension only) of an image\n    Inputs:\n        x (tensor): 4D input with the last two dimensions the spatial input\n        h0 (tensor): 4D input for the lowpass filter. Should have shape (1, 1,\n            h, 1) or (1, 1, 1, w)\n        h1 (tensor): 4D input for the highpass filter. Should have shape (1, 1,\n            h, 1) or (1, 1, 1, w)\n        mode (str): padding method\n        dim (int) - dimension of filtering. d=2 is for a vertical filter (called\n            column filtering but filters across the rows). d=3 is for a\n            horizontal filter, (called row filtering but filters across the\n            columns).\n    Returns:\n        lohi: lowpass and highpass subbands concatenated along the channel\n            dimension\n    \"\"\"\n    C = x.shape[1]\n    # Convert the dim to positive\n    d = dim % 4\n    s = (2, 1) if d == 2 else (1, 2)\n    N = x.shape[d]\n    # If h0, h1 are not tensors, make them. If they are, then assume that they\n    # are in the right order\n    if not isinstance(h0, torch.Tensor):\n        h0 = torch.tensor(np.copy(np.array(h0).ravel()[::-1]),\n                          dtype=torch.float, device=x.device)\n    if not isinstance(h1, torch.Tensor):\n        h1 = torch.tensor(np.copy(np.array(h1).ravel()[::-1]),\n                          dtype=torch.float, device=x.device)\n    L = h0.numel()\n    L2 = L // 2\n    shape = [1,1,1,1]\n    shape[d] = L\n    # If h aren't in the right shape, make them so\n    if h0.shape != tuple(shape):\n        h0 = h0.reshape(*shape)\n    if h1.shape != tuple(shape):\n        h1 = h1.reshape(*shape)\n    h = torch.cat([h0, h1] * C, dim=0)\n\n    if mode == 'per' or mode == 'periodization':\n        if x.shape[dim] % 2 == 1:\n            if d == 2:\n                x = torch.cat((x, x[:,:,-1:]), dim=2)\n            else:\n                x = torch.cat((x, x[:,:,:,-1:]), dim=3)\n            N += 1\n        x = roll(x, -L2, dim=d)\n        pad = (L-1, 0) if d == 2 else (0, L-1)\n        lohi = F.conv2d(x, h, padding=pad, stride=s, groups=C)\n        N2 = N//2\n        if d == 2:\n            lohi[:,:,:L2] = lohi[:,:,:L2] + lohi[:,:,N2:N2+L2]\n            lohi = lohi[:,:,:N2]\n        else:\n            lohi[:,:,:,:L2] = lohi[:,:,:,:L2] + lohi[:,:,:,N2:N2+L2]\n            lohi = lohi[:,:,:,:N2]\n    else:\n        # Calculate the pad size\n        outsize = pywt.dwt_coeff_len(N, L, mode=mode)\n        p = 2 * (outsize - 1) - N + L\n        if mode == 'zero':\n            # Sadly, pytorch only allows for same padding before and after, if\n            # we need to do more padding after for odd length signals, have to\n            # prepad\n            if p % 2 == 1:\n                pad = (0, 0, 0, 1) if d == 2 else (0, 1, 0, 0)\n                x = F.pad(x, pad)\n            pad = (p//2, 0) if d == 2 else (0, p//2)\n            # Calculate the high and lowpass\n            lohi = F.conv2d(x, h, padding=pad, stride=s, groups=C)\n        elif mode == 'symmetric' or mode == 'reflect' or mode == 'periodic':\n            pad = (0, 0, p//2, (p+1)//2) if d == 2 else (p//2, (p+1)//2, 0, 0)\n            x = mypad(x, pad=pad, mode=mode)\n            lohi = F.conv2d(x, h, stride=s, groups=C)\n        else:\n            raise ValueError(\"Unkown pad type: {}\".format(mode))\n\n    return lohi\n\n\n\nclass AFB2D(Function):\n    \"\"\" Does a single level 2d wavelet decomposition of an input. Does separate\n    row and column filtering by two calls to\n    :py:func:`pytorch_wavelets.dwt.lowlevel.afb1d`\n    Needs to have the tensors in the right form. Because this function defines\n    its own backward pass, saves on memory by not having to save the input\n    tensors.\n    Inputs:\n        x (torch.Tensor): Input to decompose\n        h0_row: row lowpass\n        h1_row: row highpass\n        h0_col: col lowpass\n        h1_col: col highpass\n        mode (int): use mode_to_int to get the int code here\n    We encode the mode as an integer rather than a string as gradcheck causes an\n    error when a string is provided.\n    Returns:\n        y: Tensor of shape (N, C*4, H, W)\n    \"\"\"\n    @staticmethod\n    def forward(ctx, x, h0_row, h1_row, h0_col, h1_col, mode):\n        ctx.save_for_backward(h0_row, h1_row, h0_col, h1_col)\n        ctx.shape = x.shape[-2:]\n        mode = int_to_mode(mode)\n        ctx.mode = mode\n        lohi = afb1d(x, h0_row, h1_row, mode=mode, dim=3)\n        y = afb1d(lohi, h0_col, h1_col, mode=mode, dim=2)\n        s = y.shape\n        y = y.reshape(s[0], -1, 4, s[-2], s[-1])\n        low = y[:,:,0].contiguous()\n        highs = y[:,:,1:].contiguous()\n        return low, highs\n\n    @staticmethod\n    def backward(ctx, low, highs):\n        dx = None\n        if ctx.needs_input_grad[0]:\n            mode = ctx.mode\n            h0_row, h1_row, h0_col, h1_col = ctx.saved_tensors\n            lh, hl, hh = torch.unbind(highs, dim=2)\n            lo = sfb1d(low, lh, h0_col, h1_col, mode=mode, dim=2)\n            hi = sfb1d(hl, hh, h0_col, h1_col, mode=mode, dim=2)\n            dx = sfb1d(lo, hi, h0_row, h1_row, mode=mode, dim=3)\n            if dx.shape[-2] > ctx.shape[-2] and dx.shape[-1] > ctx.shape[-1]:\n                dx = dx[:,:,:ctx.shape[-2], :ctx.shape[-1]]\n            elif dx.shape[-2] > ctx.shape[-2]:\n                dx = dx[:,:,:ctx.shape[-2]]\n            elif dx.shape[-1] > ctx.shape[-1]:\n                dx = dx[:,:,:,:ctx.shape[-1]]\n        return dx, None, None, None, None, None\n\n\ndef prep_filt_afb2d(h0_col, h1_col, h0_row=None, h1_row=None, device=device):\n    \"\"\"\n    Prepares the filters to be of the right form for the afb2d function.  In\n    particular, makes the tensors the right shape. It takes mirror images of\n    them as as afb2d uses conv2d which acts like normal correlation.\n    Inputs:\n        h0_col (array-like): low pass column filter bank\n        h1_col (array-like): high pass column filter bank\n        h0_row (array-like): low pass row filter bank. If none, will assume the\n            same as column filter\n        h1_row (array-like): high pass row filter bank. If none, will assume the\n            same as column filter\n        device: which device to put the tensors on to\n    Returns:\n        (h0_col, h1_col, h0_row, h1_row)\n    \"\"\"\n    h0_col, h1_col = prep_filt_afb1d(h0_col, h1_col, device)\n    if h0_row is None:\n        h0_row, h1_col = h0_col, h1_col\n    else:\n        h0_row, h1_row = prep_filt_afb1d(h0_row, h1_row, device)\n\n    h0_col = h0_col.reshape((1, 1, -1, 1))\n    h1_col = h1_col.reshape((1, 1, -1, 1))\n    h0_row = h0_row.reshape((1, 1, 1, -1))\n    h1_row = h1_row.reshape((1, 1, 1, -1))\n    return h0_col, h1_col, h0_row, h1_row\n\n\ndef prep_filt_afb1d(h0, h1, device=device):\n    \"\"\"\n    Prepares the filters to be of the right form for the afb2d function.  In\n    particular, makes the tensors the right shape. It takes mirror images of\n    them as as afb2d uses conv2d which acts like normal correlation.\n    Inputs:\n        h0 (array-like): low pass column filter bank\n        h1 (array-like): high pass column filter bank\n        device: which device to put the tensors on to\n    Returns:\n        (h0, h1)\n    \"\"\"\n    h0 = np.array(h0[::-1]).ravel()\n    h1 = np.array(h1[::-1]).ravel()\n    t = torch.get_default_dtype()\n    h0 = torch.tensor(h0, device=device, dtype=t).reshape((1, 1, -1))\n    h1 = torch.tensor(h1, device=device, dtype=t).reshape((1, 1, -1))\n    return h0, h1\n\nclass DWTForward(nn.Module):\n    \"\"\" Performs a 2d DWT Forward decomposition of an image\n    Args:\n        J (int): Number of levels of decomposition\n        wave (str or pywt.Wavelet or tuple(ndarray)): Which wavelet to use.\n            Can be:\n            1) a string to pass to pywt.Wavelet constructor\n            2) a pywt.Wavelet class\n            3) a tuple of numpy arrays, either (h0, h1) or (h0_col, h1_col, h0_row, h1_row)\n        mode (str): 'zero', 'symmetric', 'reflect' or 'periodization'. The\n            padding scheme\n        \"\"\"\n    def __init__(self, J=1, wave='db1', mode='zero'):\n        super().__init__()\n        if isinstance(wave, str):\n            wave = pywt.Wavelet(wave)\n        if isinstance(wave, pywt.Wavelet):\n            h0_col, h1_col = wave.dec_lo, wave.dec_hi\n            h0_row, h1_row = h0_col, h1_col\n        else:\n            if len(wave) == 2:\n                h0_col, h1_col = wave[0], wave[1]\n                h0_row, h1_row = h0_col, h1_col\n            elif len(wave) == 4:\n                h0_col, h1_col = wave[0], wave[1]\n                h0_row, h1_row = wave[2], wave[3]\n\n        # Prepare the filters\n        filts = prep_filt_afb2d(h0_col, h1_col, h0_row, h1_row)\n        self.register_buffer('h0_col', filts[0])\n        self.register_buffer('h1_col', filts[1])\n        self.register_buffer('h0_row', filts[2])\n        self.register_buffer('h1_row', filts[3])\n        self.J = J\n        self.mode = mode\n\n    def forward(self, x):\n        \"\"\" Forward pass of the DWT.\n        Args:\n            x (tensor): Input of shape :math:`(N, C_{in}, H_{in}, W_{in})`\n        Returns:\n            (yl, yh)\n                tuple of lowpass (yl) and bandpass (yh) coefficients.\n                yh is a list of length J with the first entry\n                being the finest scale coefficients. yl has shape\n                :math:`(N, C_{in}, H_{in}', W_{in}')` and yh has shape\n                :math:`list(N, C_{in}, 3, H_{in}'', W_{in}'')`. The new\n                dimension in yh iterates over the LH, HL and HH coefficients.\n        Note:\n            :math:`H_{in}', W_{in}', H_{in}'', W_{in}''` denote the correctly\n            downsampled shapes of the DWT pyramid.\n        \"\"\"\n        yh = []\n        ll = x\n        mode = mode_to_int(self.mode)\n\n        # Do a multilevel transform\n        for j in range(self.J):\n            # Do 1 level of the transform\n            ll, high = AFB2D.apply(\n                ll, self.h0_col, self.h1_col, self.h0_row, self.h1_row, mode)\n            yh.append(high)\n\n        return ll, yh\n\n\n","metadata":{"id":"rsC9JMo68dvh","execution":{"iopub.status.busy":"2021-09-30T13:37:59.383368Z","iopub.execute_input":"2021-09-30T13:37:59.383698Z","iopub.status.idle":"2021-09-30T13:37:59.457Z","shell.execute_reply.started":"2021-09-30T13:37:59.383654Z","shell.execute_reply":"2021-09-30T13:37:59.455749Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class LayerNorm(nn.Module): # layernorm, but done in the channel dimension #1\n    def __init__(self, dim, eps = 1e-5):\n        super().__init__()\n        self.eps = eps\n        self.g = nn.Parameter(torch.ones(1, dim, 1, 1))\n        self.b = nn.Parameter(torch.zeros(1, dim, 1, 1))\n\n    def forward(self, x):\n        std = torch.var(x, dim = 1, unbiased = False, keepdim = True).sqrt()\n        mean = torch.mean(x, dim = 1, keepdim = True)\n        return (x - mean) / (std + self.eps) * self.g + self.b\n\nclass Waveblock(nn.Module):\n    def __init__(\n        self,\n        *,\n        mult_dim = 32,\n        conv = False,\n        conv_kernel = 1,\n        ff_channel = 16,\n        final_dim = 16,\n        dropout = 0.,\n    ):\n        super().__init__()\n        \n        if conv == True:\n            self.feedforward = nn.Sequential(\n                nn.Conv2d(final_dim * 4, mult_dim, conv_kernel),\n                nn.GELU(),\n                nn.Dropout(dropout),\n                nn.Conv2d(mult_dim, ff_channel, conv_kernel),\n                nn.Dropout(dropout)\n            )\n        else:\n            self.feedforward = nn.Sequential(\n                Rearrange('b c h w -> b h w c'),\n                nn.Linear(final_dim * 4, mult_dim),\n                nn.GELU(),\n                nn.Dropout(dropout),\n                nn.Linear(mult_dim, ff_channel),\n                nn.Dropout(dropout),\n                Rearrange('b h w c -> b c h w')\n            )\n\n        self.ff1 = nn.ConvTranspose2d(ff_channel, int(final_dim/4), 4, stride=2, padding=1)\n        self.ff2 = nn.ConvTranspose2d(ff_channel, int(final_dim/4), 6, stride=4, padding=1)\n        self.ff3 = nn.ConvTranspose2d(ff_channel, int(final_dim/4), 10, stride=8, padding=1)\n        self.ff4 = nn.ConvTranspose2d(ff_channel, int(final_dim/4), 18, stride=16, padding=1)\n\n            \n        \n    def forward(self, x):\n        b, c, h, w = x.shape\n        \n        xf1 = DWTForward(J=1, mode='zero', wave='db1').cuda()\n        xf2 = DWTForward(J=2, mode='zero', wave='db1').cuda()\n        xf3 = DWTForward(J=3, mode='zero', wave='db1').cuda()\n        xf4 = DWTForward(J=4, mode='zero', wave='db1').cuda()\n        \n        Y1, Yh = xf1(x)\n        Y2, Yh = xf2(x)\n        Y3, Yh = xf3(x)\n        Y4, Yh = xf4(x)\n\n        x1 = torch.reshape(Yh[0], (b, c*3, int(h/2), int(h/2)))\n        x2 = torch.reshape(Yh[1], (b, c*3, int(h/4), int(w/4)))\n        x3 = torch.reshape(Yh[2], (b, c*3, int(h/8), int(w/8)))\n        x4 = torch.reshape(Yh[3], (b, c*3, int(h/16), int(w/16)))\n\n        x1 = torch.cat((Y1,x1), dim = 1)\n        x2 = torch.cat((Y2,x2), dim = 1)\n        x3 = torch.cat((Y3,x3), dim = 1)\n        x4 = torch.cat((Y4,x4), dim = 1)\n\n        x1 = self.feedforward(x1)\n        x2 = self.feedforward(x2)\n        x3 = self.feedforward(x3)\n        x4 = self.feedforward(x4)\n\n        x1 = self.ff1(x1)\n        x2 = self.ff2(x2)\n        x3 = self.ff3(x3)\n        x4 = self.ff4(x4)\n        \n        x = torch.cat((x1,x2,x3,x4), dim = 1)\n        \n        return x \n        ","metadata":{"execution":{"iopub.status.busy":"2021-09-30T13:37:59.458983Z","iopub.execute_input":"2021-09-30T13:37:59.459702Z","iopub.status.idle":"2021-09-30T13:37:59.487774Z","shell.execute_reply.started":"2021-09-30T13:37:59.459656Z","shell.execute_reply":"2021-09-30T13:37:59.486395Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nclass Wavelet2(nn.Module):\n    def __init__(\n        self,\n        *,\n        num_classes,\n        depth,\n        mult_dim = 32,\n        conv = False,\n        conv_kernel = 1,\n        ff_channel = 16,\n        final_dim = 16,\n        dropout = 0.,\n    ):\n        super().__init__()\n        self.layers = nn.ModuleList([])\n        for _ in range(depth):\n            self.layers.append(nn.Sequential(\n                Waveblock(mult_dim = mult_dim, conv = conv, conv_kernel = conv_kernel, ff_channel = ff_channel, final_dim = final_dim, dropout = dropout),\n            ))\n\n        self.pool = nn.Sequential(\n            nn.AdaptiveAvgPool2d(1),\n            Rearrange('... () () -> ...')\n        )\n\n        self.mlp_head = nn.Linear(final_dim, num_classes)\n        self.conv = nn.Sequential(\n            nn.Conv2d(3, int(final_dim/2), 3, 1, 1),\n            nn.Conv2d(int(final_dim/2), final_dim, 3, 1, 1)\n        )\n\n    def forward(self, img):\n\n        x = self.conv(img)\n        \n        for attn in self.layers:\n            x = attn(x) + x\n\n        x = self.pool(x)\n        out = self.mlp_head(x)\n\n        return out","metadata":{"id":"t2EOrhtOSGd8","execution":{"iopub.status.busy":"2021-09-30T13:37:59.490938Z","iopub.execute_input":"2021-09-30T13:37:59.491612Z","iopub.status.idle":"2021-09-30T13:37:59.534898Z","shell.execute_reply.started":"2021-09-30T13:37:59.491522Z","shell.execute_reply":"2021-09-30T13:37:59.533781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Wavelet2(\n    num_classes = 10,\n    depth = 5,\n    mult_dim = 64,\n    conv = True,\n    conv_kernel = 1,\n    ff_channel = 64,\n    final_dim = 64,\n    dropout = 0.5\n)\n    \nmodel.to(device)\nprint(summary(model, (3,32,32)))    \nprint(torch.cuda.get_device_properties(device))","metadata":{"id":"FG5swa8-SrjT","outputId":"e935265d-6735-462d-c6e6-71fc81e9f1bb","execution":{"iopub.status.busy":"2021-09-30T13:37:59.536748Z","iopub.execute_input":"2021-09-30T13:37:59.537087Z","iopub.status.idle":"2021-09-30T13:38:06.164817Z","shell.execute_reply.started":"2021-09-30T13:37:59.537043Z","shell.execute_reply":"2021-09-30T13:38:06.163807Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model.load_state_dict(torch.load('../input/sota1data/WaveNet2sota (1).pth'))","metadata":{"execution":{"iopub.status.busy":"2021-09-30T13:38:06.167132Z","iopub.execute_input":"2021-09-30T13:38:06.167454Z","iopub.status.idle":"2021-09-30T13:38:06.175309Z","shell.execute_reply.started":"2021-09-30T13:38:06.16741Z","shell.execute_reply":"2021-09-30T13:38:06.174268Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\nscaler = torch.cuda.amp.GradScaler()\n# optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\ntop1 = []\ntop5 = []\noptimizer = optim.AdamW(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.01, amsgrad=False)\n\nfor epoch in range(100):  # loop over the dataset multiple times\n    t0 = time.time()\n    epoch_accuracy = 0\n    epoch_loss = 0\n    running_loss = 0.0\n    model.train()\n\n    for i, data in enumerate(trainloader, 0):\n        # get the inputs; data is a list of [inputs, labels]\n        inputs, labels = data[0].to(device), data[1].to(device)\n        optimizer.zero_grad()\n        outputs = model(inputs)\n        with torch.cuda.amp.autocast():\n            loss = criterion(outputs, labels)\n        scaler.scale(loss).backward()\n        scaler.step(optimizer)\n        scaler.update()\n\n\n        acc = (outputs.argmax(dim=1) == labels).float().mean()\n        epoch_accuracy += acc / len(trainloader)\n        epoch_loss += loss / len(trainloader)\n    \n        # print statistics\n        running_loss += loss.item()\n        if i % 200 == 199:    # print every 2000 mini-batches\n            print('[%d, %5d] loss: %.3f' %\n                  (epoch + 1, i + 1, running_loss / 2000))\n            running_loss = 0.0\n    correct = 0\n    total = 0\n    correct_1=0\n    correct_5=0\n    c = 0\n    model.eval()\n    with torch.no_grad():\n        for data in testloader:\n            images, labels = data[0].to(device), data[1].to(device)\n            outputs = model(images)\n#         outputs = net(images)\n\n            _, predicted = torch.max(outputs.data, 1)\n            res = accuracy(outputs, labels)\n            correct_1 += res[0][0].float()\n            correct_5 += res[1][0].float()\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n            c += 1\n        \n    print(f\"Epoch : {epoch+1} - loss : {epoch_loss:.4f} - acc: {epoch_accuracy:.4f} - Top 1: {correct_1/c} - Top 5: {correct_5/c} - Time: {time.time() - t0}\\n\")\n    top1.append(correct_1/c)\n    top5.append(correct_5/c)\n    if float(correct_1/c) >= float(max(top1)):\n        PATH = 'WaveNet.pth'\n        torch.save(model.state_dict(), PATH)\n        print(1)\nprint('Finished Training')","metadata":{"id":"89xbgsZHS23A","outputId":"fc831c09-b27a-4721-a4df-392e3a8aa272","execution":{"iopub.status.busy":"2021-09-30T13:38:06.179062Z","iopub.execute_input":"2021-09-30T13:38:06.179311Z"},"trusted":true},"execution_count":null,"outputs":[]}]}